{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bc88cbb",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-09-20T22:58:53.033368Z",
     "iopub.status.busy": "2022-09-20T22:58:53.032790Z",
     "iopub.status.idle": "2022-09-20T22:58:53.051215Z",
     "shell.execute_reply": "2022-09-20T22:58:53.049892Z"
    },
    "papermill": {
     "duration": 0.030486,
     "end_time": "2022-09-20T22:58:53.054112",
     "exception": false,
     "start_time": "2022-09-20T22:58:53.023626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/graduate-admissions/Admission_Predict.csv\n",
      "/kaggle/input/graduate-admissions/Admission_Predict_Ver1.1.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7d8c15b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T22:58:53.071653Z",
     "iopub.status.busy": "2022-09-20T22:58:53.070327Z",
     "iopub.status.idle": "2022-09-20T22:58:53.096089Z",
     "shell.execute_reply": "2022-09-20T22:58:53.094419Z"
    },
    "papermill": {
     "duration": 0.040169,
     "end_time": "2022-09-20T22:58:53.101719",
     "exception": false,
     "start_time": "2022-09-20T22:58:53.061550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/graduate-admissions/Admission_Predict_Ver1.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0c4b709",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T22:58:53.116297Z",
     "iopub.status.busy": "2022-09-20T22:58:53.115821Z",
     "iopub.status.idle": "2022-09-20T22:58:53.152864Z",
     "shell.execute_reply": "2022-09-20T22:58:53.151557Z"
    },
    "papermill": {
     "duration": 0.047365,
     "end_time": "2022-09-20T22:58:53.155483",
     "exception": false,
     "start_time": "2022-09-20T22:58:53.108118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d805a31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T22:58:53.169921Z",
     "iopub.status.busy": "2022-09-20T22:58:53.169428Z",
     "iopub.status.idle": "2022-09-20T22:58:53.176561Z",
     "shell.execute_reply": "2022-09-20T22:58:53.175665Z"
    },
    "papermill": {
     "duration": 0.0168,
     "end_time": "2022-09-20T22:58:53.178560",
     "exception": false,
     "start_time": "2022-09-20T22:58:53.161760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e4f1e94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T22:58:53.193983Z",
     "iopub.status.busy": "2022-09-20T22:58:53.192660Z",
     "iopub.status.idle": "2022-09-20T22:58:53.209409Z",
     "shell.execute_reply": "2022-09-20T22:58:53.208136Z"
    },
    "papermill": {
     "duration": 0.026995,
     "end_time": "2022-09-20T22:58:53.211831",
     "exception": false,
     "start_time": "2022-09-20T22:58:53.184836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum() # to check for duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d5f8c64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T22:58:53.226687Z",
     "iopub.status.busy": "2022-09-20T22:58:53.226224Z",
     "iopub.status.idle": "2022-09-20T22:58:53.255183Z",
     "shell.execute_reply": "2022-09-20T22:58:53.253548Z"
    },
    "papermill": {
     "duration": 0.040012,
     "end_time": "2022-09-20T22:58:53.258359",
     "exception": false,
     "start_time": "2022-09-20T22:58:53.218347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         500 non-null    int64  \n",
      " 1   GRE Score          500 non-null    int64  \n",
      " 2   TOEFL Score        500 non-null    int64  \n",
      " 3   University Rating  500 non-null    int64  \n",
      " 4   SOP                500 non-null    float64\n",
      " 5   LOR                500 non-null    float64\n",
      " 6   CGPA               500 non-null    float64\n",
      " 7   Research           500 non-null    int64  \n",
      " 8   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b09f3199",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T22:58:53.273735Z",
     "iopub.status.busy": "2022-09-20T22:58:53.273237Z",
     "iopub.status.idle": "2022-09-20T22:58:53.280553Z",
     "shell.execute_reply": "2022-09-20T22:58:53.279401Z"
    },
    "papermill": {
     "duration": 0.017497,
     "end_time": "2022-09-20T22:58:53.282706",
     "exception": false,
     "start_time": "2022-09-20T22:58:53.265209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['Serial No.'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51ff846a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T22:58:53.298222Z",
     "iopub.status.busy": "2022-09-20T22:58:53.296914Z",
     "iopub.status.idle": "2022-09-20T22:58:53.312413Z",
     "shell.execute_reply": "2022-09-20T22:58:53.311452Z"
    },
    "papermill": {
     "duration": 0.025454,
     "end_time": "2022-09-20T22:58:53.314614",
     "exception": false,
     "start_time": "2022-09-20T22:58:53.289160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7a0b323",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T22:58:53.329870Z",
     "iopub.status.busy": "2022-09-20T22:58:53.329364Z",
     "iopub.status.idle": "2022-09-20T22:58:53.336580Z",
     "shell.execute_reply": "2022-09-20T22:58:53.335249Z"
    },
    "papermill": {
     "duration": 0.017837,
     "end_time": "2022-09-20T22:58:53.339106",
     "exception": false,
     "start_time": "2022-09-20T22:58:53.321269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = df.iloc[:,0:-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2571f29e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T22:58:53.354688Z",
     "iopub.status.busy": "2022-09-20T22:58:53.354247Z",
     "iopub.status.idle": "2022-09-20T22:58:54.532218Z",
     "shell.execute_reply": "2022-09-20T22:58:54.531001Z"
    },
    "papermill": {
     "duration": 1.189345,
     "end_time": "2022-09-20T22:58:54.535342",
     "exception": false,
     "start_time": "2022-09-20T22:58:53.345997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f2a0a20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T22:58:54.552279Z",
     "iopub.status.busy": "2022-09-20T22:58:54.551794Z",
     "iopub.status.idle": "2022-09-20T22:58:54.570594Z",
     "shell.execute_reply": "2022-09-20T22:58:54.569255Z"
    },
    "papermill": {
     "duration": 0.030835,
     "end_time": "2022-09-20T22:58:54.573008",
     "exception": false,
     "start_time": "2022-09-20T22:58:54.542173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>310</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>318</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>300</td>\n",
       "      <td>101</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>300</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>322</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>307</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>321</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>326</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>300</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "238        310          104                  3  2.0   3.5  8.37         0\n",
       "438        318          110                  1  2.5   3.5  8.54         1\n",
       "475        300          101                  3  3.5   2.5  7.88         0\n",
       "58         300           99                  1  3.0   2.0  6.80         1\n",
       "380        322          104                  3  3.5   4.0  8.84         1\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "255        307          110                  4  4.0   4.5  8.37         0\n",
       "72         321          111                  5  5.0   5.0  9.45         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "235        326          111                  5  4.5   4.0  9.23         1\n",
       "37         300          105                  1  1.0   2.0  7.80         0\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6a0e0b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T22:58:54.589374Z",
     "iopub.status.busy": "2022-09-20T22:58:54.588879Z",
     "iopub.status.idle": "2022-09-20T22:58:54.602337Z",
     "shell.execute_reply": "2022-09-20T22:58:54.601259Z"
    },
    "papermill": {
     "duration": 0.024678,
     "end_time": "2022-09-20T22:58:54.604723",
     "exception": false,
     "start_time": "2022-09-20T22:58:54.580045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "348ac3bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T22:58:54.620669Z",
     "iopub.status.busy": "2022-09-20T22:58:54.620208Z",
     "iopub.status.idle": "2022-09-20T22:58:54.628585Z",
     "shell.execute_reply": "2022-09-20T22:58:54.627402Z"
    },
    "papermill": {
     "duration": 0.019223,
     "end_time": "2022-09-20T22:58:54.630910",
     "exception": false,
     "start_time": "2022-09-20T22:58:54.611687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4       , 0.42857143, 0.5       , ..., 0.57142857, 0.50320513,\n",
       "        0.        ],\n",
       "       [0.56      , 0.64285714, 0.        , ..., 0.57142857, 0.55769231,\n",
       "        1.        ],\n",
       "       [0.2       , 0.32142857, 0.5       , ..., 0.28571429, 0.34615385,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.7       , 0.53571429, 0.5       , ..., 0.57142857, 0.74038462,\n",
       "        1.        ],\n",
       "       [0.72      , 0.67857143, 1.        , ..., 0.71428571, 0.77884615,\n",
       "        1.        ],\n",
       "       [0.2       , 0.46428571, 0.        , ..., 0.14285714, 0.32051282,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97376720",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T22:58:54.647635Z",
     "iopub.status.busy": "2022-09-20T22:58:54.646603Z",
     "iopub.status.idle": "2022-09-20T22:59:01.129729Z",
     "shell.execute_reply": "2022-09-20T22:59:01.128245Z"
    },
    "papermill": {
     "duration": 6.495006,
     "end_time": "2022-09-20T22:59:01.133226",
     "exception": false,
     "start_time": "2022-09-20T22:58:54.638220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Building the ANN model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfacd303",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T22:59:01.149865Z",
     "iopub.status.busy": "2022-09-20T22:59:01.149102Z",
     "iopub.status.idle": "2022-09-20T22:59:01.288290Z",
     "shell.execute_reply": "2022-09-20T22:59:01.286913Z"
    },
    "papermill": {
     "duration": 0.150682,
     "end_time": "2022-09-20T22:59:01.291188",
     "exception": false,
     "start_time": "2022-09-20T22:59:01.140506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 22:59:01.188501: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(7, activation='relu', input_dim=7)) # for input layer\n",
    "model.add(Dense(7, activation='relu'))\n",
    "model.add(Dense(1, activation='linear')) # for output layer shall always be linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aee03e70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T22:59:01.307185Z",
     "iopub.status.busy": "2022-09-20T22:59:01.306703Z",
     "iopub.status.idle": "2022-09-20T22:59:01.313740Z",
     "shell.execute_reply": "2022-09-20T22:59:01.312297Z"
    },
    "papermill": {
     "duration": 0.019209,
     "end_time": "2022-09-20T22:59:01.317398",
     "exception": false,
     "start_time": "2022-09-20T22:59:01.298189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 56        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 8         \n",
      "=================================================================\n",
      "Total params: 120\n",
      "Trainable params: 120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2833542f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T22:59:01.334559Z",
     "iopub.status.busy": "2022-09-20T22:59:01.334095Z",
     "iopub.status.idle": "2022-09-20T22:59:01.349706Z",
     "shell.execute_reply": "2022-09-20T22:59:01.348436Z"
    },
    "papermill": {
     "duration": 0.027628,
     "end_time": "2022-09-20T22:59:01.353096",
     "exception": false,
     "start_time": "2022-09-20T22:59:01.325468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3503b82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T22:59:01.370449Z",
     "iopub.status.busy": "2022-09-20T22:59:01.370007Z",
     "iopub.status.idle": "2022-09-20T22:59:29.845678Z",
     "shell.execute_reply": "2022-09-20T22:59:29.844368Z"
    },
    "papermill": {
     "duration": 28.487776,
     "end_time": "2022-09-20T22:59:29.848611",
     "exception": false,
     "start_time": "2022-09-20T22:59:01.360835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-20 22:59:01.460658: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "10/10 [==============================] - 1s 23ms/step - loss: 0.5716 - val_loss: 0.4823\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4224 - val_loss: 0.3375\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2948 - val_loss: 0.2230\n",
      "Epoch 4/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1979 - val_loss: 0.1388\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1258 - val_loss: 0.0839\n",
      "Epoch 6/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0797 - val_loss: 0.0520\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0533 - val_loss: 0.0357\n",
      "Epoch 8/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.0286\n",
      "Epoch 9/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0337 - val_loss: 0.0260\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0311 - val_loss: 0.0251\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0297 - val_loss: 0.0245\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0285 - val_loss: 0.0236\n",
      "Epoch 13/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0273 - val_loss: 0.0224\n",
      "Epoch 14/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0257 - val_loss: 0.0210\n",
      "Epoch 15/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0238 - val_loss: 0.0195\n",
      "Epoch 16/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0220 - val_loss: 0.0174\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0201 - val_loss: 0.0161\n",
      "Epoch 18/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0188 - val_loss: 0.0151\n",
      "Epoch 19/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0179 - val_loss: 0.0142\n",
      "Epoch 20/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0170 - val_loss: 0.0134\n",
      "Epoch 21/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0164 - val_loss: 0.0129\n",
      "Epoch 22/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0158 - val_loss: 0.0123\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0152 - val_loss: 0.0118\n",
      "Epoch 24/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0113\n",
      "Epoch 25/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0108\n",
      "Epoch 26/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0103\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0097\n",
      "Epoch 28/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0123 - val_loss: 0.0091\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0117 - val_loss: 0.0083\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0110 - val_loss: 0.0078\n",
      "Epoch 31/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.0074\n",
      "Epoch 32/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.0070\n",
      "Epoch 33/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0097 - val_loss: 0.0067\n",
      "Epoch 34/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0065\n",
      "Epoch 35/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0090 - val_loss: 0.0063\n",
      "Epoch 36/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0088 - val_loss: 0.0061\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0060\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0058\n",
      "Epoch 39/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0057\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0079 - val_loss: 0.0056\n",
      "Epoch 41/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0077 - val_loss: 0.0055\n",
      "Epoch 42/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.0055\n",
      "Epoch 43/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0054\n",
      "Epoch 44/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0073 - val_loss: 0.0053\n",
      "Epoch 45/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.0053\n",
      "Epoch 46/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0071 - val_loss: 0.0053\n",
      "Epoch 47/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0052\n",
      "Epoch 48/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0067 - val_loss: 0.0051\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 51/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 52/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 53/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 54/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0063 - val_loss: 0.0048\n",
      "Epoch 55/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 57/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0059 - val_loss: 0.0047\n",
      "Epoch 61/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 62/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 64/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 66/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 67/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 68/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 69/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 70/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 71/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 72/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 73/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 74/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 76/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 77/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 78/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 79/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 80/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 81/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 82/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 83/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 84/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 85/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0041\n",
      "Epoch 86/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 88/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 89/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 90/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 91/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 92/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 93/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 96/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 97/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 98/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 99/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 100/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 101/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 102/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 103/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 104/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 105/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 106/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 107/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 109/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 110/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 111/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 112/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 113/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 114/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 115/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 116/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 118/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 119/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 120/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 121/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 122/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 123/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 124/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 125/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 126/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 127/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 128/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 129/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 130/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 131/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 132/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 133/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 134/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 135/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 136/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 137/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 138/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 139/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 140/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 141/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 142/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 143/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 144/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 145/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 146/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 147/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 148/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 149/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 150/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 151/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 152/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 153/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 154/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 155/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 156/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 157/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 158/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 159/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 160/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 161/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 162/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 163/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 164/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 165/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 166/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 167/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 168/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 169/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 170/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 171/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 172/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 173/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 174/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 175/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 176/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 177/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 178/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 179/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 180/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 181/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 182/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 183/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 184/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 185/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 186/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 187/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 188/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 189/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 190/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 191/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 192/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 193/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 194/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 195/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 196/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 197/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 198/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 199/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 200/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 201/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 202/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 203/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 204/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 205/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 206/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 207/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 208/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 209/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 210/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 211/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 212/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 213/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 214/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 215/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 216/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 217/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 218/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 219/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 220/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 221/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 222/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 223/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 224/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 225/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 226/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 227/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 228/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 229/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 230/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 231/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 232/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 233/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 234/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 235/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 236/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 237/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 238/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 239/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 240/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 241/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 242/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 243/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 244/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 245/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 246/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 247/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 248/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 249/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 250/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 251/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 252/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 253/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 254/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 255/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 256/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 257/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 258/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 259/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 260/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 261/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 262/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 263/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 264/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 265/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 266/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 267/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 268/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 269/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 270/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 271/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 272/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 273/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 274/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 275/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 276/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 277/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 278/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 279/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 280/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 281/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 282/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 283/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 284/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 285/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 286/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 287/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 288/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 289/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 290/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 291/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 292/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 293/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 294/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 295/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 296/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 297/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 298/500\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 299/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 300/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 301/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 302/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 303/500\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 304/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 305/500\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 306/500\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 307/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 308/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 309/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 310/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 311/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 312/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 313/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 314/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 315/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 316/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 317/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 318/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 319/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 320/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 321/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 322/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 323/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 324/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 325/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 326/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 327/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 328/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 329/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 330/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 331/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 332/500\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 333/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 334/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 335/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 336/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 337/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 338/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 339/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 340/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 341/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 342/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 343/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 344/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 345/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 346/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 347/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 348/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 349/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 350/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 351/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 352/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 353/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 354/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 355/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 356/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 357/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 358/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 359/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 360/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 361/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 362/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 363/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 364/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 365/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 366/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 367/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 368/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 369/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 370/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 371/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 372/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 373/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 374/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 375/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 376/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 377/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 378/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 379/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 380/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 381/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 382/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 383/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 384/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 385/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 386/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 387/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 388/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 389/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 390/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 391/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 392/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 393/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 394/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 395/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 396/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 397/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 398/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 399/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 400/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 401/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 402/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 403/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 404/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 405/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 406/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 407/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 408/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 409/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 410/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 411/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 412/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 413/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 414/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 415/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 416/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 417/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 418/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 419/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 420/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 421/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 422/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 423/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 424/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 425/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 426/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 427/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 428/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 429/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 430/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 431/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 432/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 433/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 434/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 435/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 436/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 437/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 438/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 439/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 440/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 441/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 442/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 443/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 444/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 445/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 446/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 447/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 448/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 449/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 450/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 451/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 452/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 453/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 454/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 455/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 456/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 457/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 458/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 459/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 460/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 461/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 462/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 463/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 464/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 465/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 466/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 467/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 468/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 469/500\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 470/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 471/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 472/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 473/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 474/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 475/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 476/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 477/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 478/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 479/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 480/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 481/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 482/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 483/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 484/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 485/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 486/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 487/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 488/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 489/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 490/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 491/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 492/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 493/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 494/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 495/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 496/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 497/500\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 498/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 499/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 500/500\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0038\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train_scaled, y_train, epochs=500, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a1a9d84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T22:59:29.989694Z",
     "iopub.status.busy": "2022-09-20T22:59:29.989224Z",
     "iopub.status.idle": "2022-09-20T22:59:30.142614Z",
     "shell.execute_reply": "2022-09-20T22:59:30.141251Z"
    },
    "papermill": {
     "duration": 0.225883,
     "end_time": "2022-09-20T22:59:30.145587",
     "exception": false,
     "start_time": "2022-09-20T22:59:29.919704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "807039ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T22:59:30.286641Z",
     "iopub.status.busy": "2022-09-20T22:59:30.286160Z",
     "iopub.status.idle": "2022-09-20T22:59:30.294507Z",
     "shell.execute_reply": "2022-09-20T22:59:30.293266Z"
    },
    "papermill": {
     "duration": 0.082876,
     "end_time": "2022-09-20T22:59:30.298116",
     "exception": false,
     "start_time": "2022-09-20T22:59:30.215240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7626966706748093"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c021f01f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-20T22:59:30.439366Z",
     "iopub.status.busy": "2022-09-20T22:59:30.438573Z",
     "iopub.status.idle": "2022-09-20T22:59:30.672597Z",
     "shell.execute_reply": "2022-09-20T22:59:30.671613Z"
    },
    "papermill": {
     "duration": 0.307461,
     "end_time": "2022-09-20T22:59:30.675193",
     "exception": false,
     "start_time": "2022-09-20T22:59:30.367732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff4b1fe9c10>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 50.319971,
   "end_time": "2022-09-20T22:59:33.543065",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-09-20T22:58:43.223094",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
